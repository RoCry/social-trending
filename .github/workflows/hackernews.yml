name: HackerNews Crawler

on:
  push:
    branches:
      - master
  schedule:
    - cron: '0 * * * *'  # Run every hour
  workflow_dispatch:  # Allow manual trigger

jobs:
  crawl-hackernews:
    runs-on: ubuntu-latest
    permissions:
      contents: write  # Needed for creating releases
      
    steps:
    - uses: actions/checkout@v4

    - name: Install uv
      uses: astral-sh/setup-uv@v5
    
    - name: "Set up Python"
      uses: actions/setup-python@v5
      with:
        python-version-file: "pyproject.toml"
    
    - name: Install dependencies
      run: |
        uv sync --all-extras --dev

    - name: Restore cache folder
      uses: actions/cache/restore@v4
      with:
        path: cache/
        key: hackernews-cache-${{ github.run_id }}
        restore-keys: |
          hackernews-cache-
    
    - name: Run crawler
      env:
        DEEPSEEK_API_KEY: ${{ secrets.DEEPSEEK_API_KEY }}
      run: uv run main.py
    
    - name: Save cache folder
      uses: actions/cache/save@v4
      with:
        path: cache/
        key: hackernews-cache-${{ github.run_id }}
    
    - name: Create Release
      uses: softprops/action-gh-release@v2
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      with:
        name: "HackerNews Top Stories"
        tag_name: latest
        body_path: cache/hackernews.md
        files: |
          cache/*
        prerelease: true